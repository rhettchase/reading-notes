# Class 42: Ethics

[Google and AI](https://gizmodo.com/in-reversal-google-says-its-ai-will-not-be-used-for-we-1826649327)

Google has pledged not to use its artificial intelligence (AI) technology for weapons or surveillance following protests from its employees against the company's participation in Project Maven, a Pentagon pilot program. Despite this commitment, Google will still engage with the United States military in non-offensive capacities, such as cybersecurity and search and rescue. The decision, influenced by internal dissent and employee resignations, led to the establishment of a set of AI principles aimed at guiding Google's development and use of AI in a socially responsible manner. Critics within and outside the company argue that these principles may not go far enough in preventing future involvement in military projects like Maven, calling for more explicit commitments to international human rights law and greater transparency. Google's stance reflects a broader ethical debate within the tech industry about the role of AI in military applications and surveillance, highlighting the tension between technological advancement and ethical responsibility.

[Ethical dilemma of self driving cars](https://www.theglobeandmail.com/globe-drive/culture/technology/the-ethical-dilemmas-of-self-drivingcars/article37803470/)

The ethical dilemma surrounding self-driving cars focuses on deciding who to protect in unavoidable accident scenarios, with considerations about whether to prioritize the lives of passengers, pedestrians, or even animals. Despite technological advancements, programming autonomous vehicles to make moral decisions in complex, real-world situations remains a challenge, highlighting a need for data and ethical guidelines. Germany has attempted to establish guidelines that prioritize minimizing human death without discrimination, while studies reveal a conflict between ethical principles and personal survival instincts among potential passengers. This debate underscores a broader concern about machines making pre-programmed decisions without the human capacity for judgment in critical moments, suggesting a societal double standard that favors human decision-making flaws over cold machine logic. The discourse also touches on the broader implications of relinquishing control to autonomous systems, suggesting that societal adaptation and new forms of control and interaction with technology will emerge over time.
